<pre class='metadata'>
Title: WebRTC Insertable Media using Streams
Shortname: webrtc-media-streams
Level: 1
Status: DREAM
Group: webrtc
Repository: alvestrand/webrtc-media-streams/
URL: https://alvestrand.github.io/webrtc-media-streams/
Editor: Harald Alvestrand, Google https://google.com, hta@google.com
Editor: Guido Urdaneta, Google https://google.com, guidou@google.com
Abstract: This API defines an API surface for manipulating the bits on
Abstract: MediaStreamTracks being sent via an RTCPeerConnection.
Markup Shorthands: css no, markdown yes
</pre>
<pre class='anchors'>
spec: WEBRTC; urlPrefix: https://w3c.github.io/webrtc-pc/
    type: interface
        text: RTCPeerConnection; url: #dom-rtcpeerconnection
    type: dictionary
        text: RTCConfiguration; url: #dom-rtcconfiguration
spec: WEB-CODECS; urlPrefix: https://github.com/WICG/web-codecs/
    type: interface
        text: AudioEncoder; url: #dom-audioencoder
    type: interface
        text: AudioDecoder; url: #dom-audiodecoder
    type: interface
        text: VideoEncoder; url: #dom-videoencoder
    type: interface
        text: VideoDecoder; url: #dom-videodecoder
</pre>
<pre class=biblio>
{
  "WEB-CODECS": {
     "href":
     "https://github.com/WICG/web-codecs/blob/master/explainer.md",
     "title": "Web Codecs explainer"
   }
}
</pre>
<pre class=link-defaults>
spec:streams; type:interface; text:ReadableStream
</pre>

# Introduction # {#introduction}

The [[WEBRTC-NV-USE-CASES]] document describes several functions that
can only be achieved by access to media (requirements N20-N22),
including, but not limited to:
* Funny Hats
* Machine Learning
* Virtual Reality Gaming

These use cases further require that processing can be done in worker
threads (requirement N23-N24).

Furthermore, the "trusted JavaScript cloud conferencing" use case
requires such processing to be done on encoded media, not just the raw
media.

This specification gives an interface that builds on [[WEB-CODECS]] to
provide access to such functionality while retaining the setup flow of
RTCPeerConnection.

This iteration of the specification provides access to encoded media,
which is the output of the encoder part of a codec and the input to the
decoder part of a codec.

# Terminology # {#terminology}

<p noexport>
The IDL terms <dfn type="idl-name">AudioEncoder</dfn>, <dfn>VideoEncoder</dfn>,
<dfn>AudioDecoder</dfn>, <dfn>VideoDecoder</dfn> are defined in [[WEB-CODECS]].
</p>

# Specification # {#specification}

The Streams definition doesn't use WebIDL much, but the WebRTC spec does.
This specification shows the IDL extensions for WebRTC.

It uses an extension to RTCConfiguration in order to notify the
{{RTCPeerConnection}} that insertable streams will be used, and uses
an additional API on {{RTCRtpSender}} and {{RTCRtpReceiver}} to
insert the processing into the pipeline.

<pre class="idl">
// New dictionary.
dictionary RTCInsertableStreams {
    ReadableStream readable;
    WritableStream writable;
};

// New enum for video frame types. Will eventually re-use the equivalent defined
// by WebCodecs.
enum RTCEncodedVideoFrameType {
    "empty",
    "key",
    "delta",
};

dictionary RTCFrameMetadata {
   long synchronizationSource;
   sequence&lt;long&gt; contributingSources;
};

// New interfaces to define encoded video and audio frames. Will eventually
// re-use or extend the equivalent defined in WebCodecs.
// The additionalData fields contain metadata about the frame and will
// eventually be exposed differently.
interface RTCEncodedVideoFrame {
    readonly attribute RTCEncodedVideoFrameType type;
    readonly attribute unsigned long long timestamp;
    attribute ArrayBuffer data;
    RTCFrameMetadata getMetadata();
};

interface RTCEncodedAudioFrame {
    readonly attribute unsigned long long timestamp;
    attribute ArrayBuffer data;
    RTCFrameMetadata getMetadata();
};


// New fields in RTCConfiguration
partial dictionary RTCConfiguration {
    boolean forceEncodedVideoInsertableStreams = false;
    boolean forceEncodedAudioInsertableStreams = false;
};

// New methods for RTCRtpSender and RTCRtpReceiver
partial interface RTCRtpSender {
    RTCInsertableStreams createEncodedVideoStreams();
    RTCInsertableStreams createEncodedAudioStreams();
};

partial interface RTCRtpReceiver {
    RTCInsertableStreams createEncodedVideoStreams();
    RTCInsertableStreams createEncodedAudioStreams();
};
</pre>

## Extension operation ## {#operation}

At the time when a codec is initialized as part of the encoder, and the
corresponding flag is set in the {{RTCPeerConnection}}'s {{RTCConfiguration}}
argument, ensure that the codec is disabled and produces no output.

When {{RTCRtpSender/createEncodedVideoStreams}}() or {{RTCRtpSender/createEncodedAudioStreams}}() is
called, run the following steps:

* If the kind of the sender does not match, throw a {{TypeError}} and abort these steps.
* If the data source does not permit access, throw an {{InvalidAccessError}} and abort these steps.
* Create an {{RTCInsertableStreams}} object 's'.
* Set s.readable to a ReadableStream representing the encoded data source.
* Set s.writable to a WritableStream representing the encoded data sink.
* Enable the encoded data source.
* Store 's' in an internal slot [[\streams]].
* Return 's'

When a frame is produced from the encoded data source, place it on the
[[\streams]].readable' stream.

When a frame appears on the [[\streams]].writable stream, process it as if it came
directly from the encoded data source.

# Privacy and security considerations # {#privacy}

This API gives Javascript access to the content of media streams. This
is also available from other sources, such as Canvas and WebAudio.

However, streams that are isolated (as specified in
[[WEBRTC-IDENTITY]]) or tainted with another origin, cannot be
accessed using this API, since that would break the isolation rule.

The API will allow access to some aspects of timing information that are
otherwise unavailable, which allows some fingerprinting surface.


# Examples # {#examples}

See the explainer document.


