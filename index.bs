<pre class='metadata'>
Title: WebRTC Insertable Media using Streams
Shortname: webrtc-media-streams
Level: 1
Status: DREAM
Group: webrtc
Repository: alvestrand/webrtc-media-streams/
URL: https://alvestrand.github.io/webrtc-media-streams/
Editor: Harald Alvestrand, Google https://google.com, hta@google.com
Abstract: This API defines an API surface for manipulating the bits on
Abstract: MediaStreamTracks being sent via an RTCPeerConnection.
Markup Shorthands: css no, markdown yes
</pre>
<pre class='anchors'>
spec: WEBRTC; urlPrefix: https://w3c.github.io/webrtc-pc/
    type: interface
        text: RTCPeerConnection; url: #dom-rtcpeerconnection
    type: dictionary
        text: RTCConfiguration; url: #dom-rtcconfiguration
spec: WEB-CODECS; urlPrefix: https://github.com/WICG/web-codecs/
    type: interface
        text: AudioEncoder; url: #dom-audioencoder
    type: interface
        text: AudioDecoder; url: #dom-audiodecoder
    type: interface
        text: VideoEncoder; url: #dom-videoencoder
    type: interface
        text: VideoDecoder; url: #dom-videodecoder
</pre>
<pre class=biblio>
{
  "WEB-CODECS": {
     "href":
     "https://github.com/WICG/web-codecs/blob/master/explainer.md",
     "title": "Web Codecs explainer"
   }
}
</pre>

# Introduction # {#introduction}

The [[WEBRTC-NV-USE-CASES]] document describes several functions that
can only be achieved by access to media (requirements N20-N22),
including, but not limited to:
* Funny Hats
* Machine Learning
* Virtual Reality Gaming

These use cases further require that processing can be done in worker
threads (requirement N23-N24).

Furthermore, the "trusted JavaScript cloud conferencing" use case
requires such processing to be done on encoded media, not just the raw
media.

This specification gives an interface that builds on [[WEB-CODECS]] to
provide access to such functionality while retaining the setup flow of
RTCPeerConnection.

# Terminology # {#terminology}

<p noexport>
The IDL terms <dfn type="idl-name">AudioEncoder</dfn>, <dfn>VideoEncoder</dfn>,
<dfn>AudioDecoder</dfn>, <dfn>VideoDecoder</dfn> are defined in [[WEB-CODECS]].
</p>

# Specification # {#specification}

The Streams definition doesn't use WebIDL much, but the WebRTC spec does.
This specification shows the IDL extensions for WebRTC.

It uses an extension to RTCConfiguration in order to pass the extra
decorators for encoder and decoder initialization to an {{RTCPeerConnection}}.

<pre class='idl'>
typedef (AudioEncoder or VideoEncoder) Encoder;
typedef (AudioDecoder or VideoDecoder) Decoder;

dictionary Config {
  // To Be Defined
};  

callback EncoderDecorator = Encoder(Encoder encoder, optional Config config);
callback DecoderDecorator = Decoder(Decoder encoder, optional Config config);

partial dictionary RTCConfiguration {
   EncoderDecorator encoderFactory;
   DecoderDecorator decoderFactory;
};
</pre>

## Extension operation ## {#operation}
At creation of an RTCPeerConnection, the following steps are added to
the creation algorithm:

* Let the RTCPeerConnection object have two internal slots named [[\EncoderFactory]] and [[\DecoderFactory]], initialized to null.
* If the RTCConfiguration parameter contains a value for "encoderFactory", store that in [[\EncoderFactory]].
* If the RTCConfiguration parameter contains a value for "decoderFactory", store that in [[\DecoderFactory]].

At the time when a codec is initialized as part of the encoder, run
the following steps:

* If the unencoded data source does not permit access, abort these steps. (OPEN ISSUE: How is this error surfaced?)
* Let the unencoded data source be represented by a ReadableStream called "source".
* Let the encoded data sink be represented by a WriteableStream called
* "sink".
* Let the internal encoder object be called "internalEncoder". "internalEncoder" will have a WritableStream property called "writable" (by virtue of being an instance of WebCodec).
* "internalEncoder" will have a ReadableStream property called "readable".
* If the PeerConnection's [[\EncoderFactory]] is null, pipe "source" to "writable", and pipe "readable" to "sink", and skip the rest of these steps.
* Call the function stored in [[\EncoderFactory]], using the newly initialized encoder and its parameters as arguments.
* Let the return value from the function be "encoder".
* If "encoder" has an attribute "readable", pipe it to "sink". Otherwise, pipe the "internalEncoder"'s "readable" to "sink".
* If "encoder" has an attribute "writable", pipe "source" to it. Otherwise, pipe "source" to the "internalEncoder"'s "writable".

The media will then be processed according to the rules of [[WEB-CODECS]].

# Privacy and security considerations # {#privacy}

This API gives Javascript access to the content of media streams. This
is also available from other sources, such as Canvas and WebAudio.

However, streams that are isolated (as specified in
[[WEBRTC-IDENTITY]]) or tainted with another origin, cannot be
accessed using this API, since that would break the isolation rule.


# Examples # {#examples}


